{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简介\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;&ensp;&ensp;&ensp;采用特征处理和 含有分类结果的用户数据，进行深度学习，预测用户的推送offer完成率，从而可以针对性的推送offer\n",
    "- 首先对数据进行scale预处理，并分割训练集 测试集\n",
    "- 通过线性回归初步预测 \n",
    "- 通过多种算法预测 找到最优算法\n",
    "- 对最优算法进行调参\n",
    "    \n",
    "    \n",
    "\n",
    "&ensp;&ensp;Based on user data with feature processing and classification, use deep learning to predict the completion rate of push offers for all users, so that offers can be pushed specifically and effectively\n",
    "- First perform scale preprocessing on the data, and split the training set and test set\n",
    "- Preliminary predicte through linear regression\n",
    "- Find the optimal algorithm through predictions of multiple algorithms\n",
    "- Tuning the optimal algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pklsave(model, filename):\n",
    "    \"\"\"\n",
    "    This function is to save the sklearn object\n",
    "    INPUT :\n",
    "        model : sklearn object\n",
    "        filename : filepath to saved\n",
    "    RETURN : none\n",
    "    \"\"\"\n",
    "    pickle.dump(model, open(filename,'wb'))\n",
    "    \n",
    "def pklload(filename):\n",
    "    \"\"\"\n",
    "    This function is to load the saved sklearn object\n",
    "    INPUT : filename : filepath\n",
    "    RETURN : loaded sklearn object\n",
    "    \"\"\"\n",
    "    return pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载分类数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# %% 加载用户分类数据 ,分类做成字符类别\n",
    "profile_cluster = pd.read_csv('data/profile_cluster.csv')\n",
    "# 用户id 作为 index\n",
    "profile_cluster = profile_cluster.set_index(profile_cluster.columns[0])\n",
    "\n",
    "# rename cluster name to m_1, m_2, etc\n",
    "profile_cluster['cluster'] = profile_cluster['cluster'].apply(lambda x: 'm_'+ str(x))\n",
    "\n",
    "# check for null data\n",
    "print( profile_cluster.isnull().sum().sum() ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 把特征分为 X 和 Y ， Y 包括两个rate 为预测值, X包括用户属性 和cluster\n",
    "features = ['age',\n",
    " 'income',\n",
    " 'avg_spending',\n",
    " 'gender_F',\n",
    " 'gender_M',\n",
    " 'gender_O',\n",
    " 'invalid_count',\n",
    " 'member_days_since',\n",
    " 'member_year_2013',\n",
    " 'member_year_2014',\n",
    " 'member_year_2015',\n",
    " 'member_year_2016',\n",
    " 'member_year_2017',\n",
    " 'member_year_2018',\n",
    " 'sum_spending',\n",
    " 'transaction_count', \n",
    " 'cluster']\n",
    "\n",
    "X = profile_cluster[features]\n",
    "target_cols = ['rate_comp_rec', 'rate_comp_view']\n",
    "y = profile_cluster[target_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'income', 'avg_spending', 'gender_F', 'gender_M', 'gender_O',\n",
       "       'invalid_count', 'member_days_since', 'member_year_2013',\n",
       "       'member_year_2014', 'member_year_2015', 'member_year_2016',\n",
       "       'member_year_2017', 'member_year_2018', 'sum_spending',\n",
       "       'transaction_count', 'cluster_m_0', 'cluster_m_1', 'cluster_m_10',\n",
       "       'cluster_m_11', 'cluster_m_2', 'cluster_m_3', 'cluster_m_4',\n",
       "       'cluster_m_5', 'cluster_m_6', 'cluster_m_7', 'cluster_m_8',\n",
       "       'cluster_m_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster列 做成 onehot\n",
    "\n",
    "X_one_hot = pd.get_dummies(X)\n",
    "\n",
    "def one_hot(df):\n",
    "    return pd.get_dummies(df)\n",
    "X_one_hot.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "def scaling(features):\n",
    "    scale = StandardScaler()\n",
    "    scale.fit(features)\n",
    "    features_std = pd.DataFrame(scale.transform(features), index= features.index, columns=features.columns)\n",
    "    return features_std\n",
    "\n",
    "X_std = scaling(X_one_hot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_train_test(features, target):\n",
    "    \n",
    "    \"\"\" Split : Train - Test \"\"\"\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    X_train, X_test, y_train, y_test = tts(features, target, test_size=0.33, random_state=42)   \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# as feature scaling will be included in model pipeline\n",
    "# the data will be split after performing one hot encoding.\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test(X_one_hot, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.4084 with stdev 0.0267\n",
      "MSE: 0.0633 with stdev 0.0033\n"
     ]
    }
   ],
   "source": [
    "# 设定随机种子43 用 LinearRegression 预测，r2_arr和 mean_squared_error来评价\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "estimators = [('standardize', StandardScaler()),\n",
    "             ('reg', MultiOutputRegressor(LinearRegression()))]\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed) # ？？？？？？？？？？？？？？？？\n",
    "results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=['r2','neg_mean_squared_error'])\n",
    "\n",
    "r2_arr = results['test_r2']\n",
    "mse_arr = results['test_neg_mean_squared_error']*-1\n",
    "\n",
    "print(f\"R^2: {r2_arr.mean():.4f} with stdev {r2_arr.std():.4f}\")\n",
    "print(f\"MSE: {mse_arr.mean():.4f} with stdev {mse_arr.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Finding  alogrithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a dict of standard models to evaluate {name:object} for MultiOutputRegressor\n",
    "def get_models_multioutput(models=dict()):\n",
    "    # linear models\n",
    "    models['lr'] = MultiOutputRegressor(LinearRegression())\n",
    "    alpha = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for a in alpha:\n",
    "        models['lasso-'+str(a)] = MultiOutputRegressor(Lasso(alpha=a))\n",
    "    for a in alpha:\n",
    "        models['ridge-'+str(a)] = MultiOutputRegressor(Ridge(alpha=a))\n",
    "    for a1 in alpha:\n",
    "        for a2 in alpha:\n",
    "            name = 'en-' + str(a1) + '-' + str(a2)\n",
    "            models[name] = MultiOutputRegressor(ElasticNet(a1, a2))\n",
    "    models['huber'] = MultiOutputRegressor(HuberRegressor())\n",
    "    models['lars'] = MultiOutputRegressor(Lars())\n",
    "    models['llars'] = MultiOutputRegressor(LassoLars())\n",
    "    models['pa'] = MultiOutputRegressor(PassiveAggressiveRegressor(max_iter=1000, tol=1e-3))\n",
    "    models['ranscac'] = MultiOutputRegressor(RANSACRegressor())\n",
    "    models['sgd'] = MultiOutputRegressor(SGDRegressor(max_iter=1000, tol=1e-3))\n",
    "    models['theil'] = MultiOutputRegressor(TheilSenRegressor())\n",
    "    # non-linear models\n",
    "    n_neighbors = range(1, 21)\n",
    "    for k in n_neighbors:\n",
    "        models['knn-'+str(k)] = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=k))\n",
    "    models['cart'] = MultiOutputRegressor(DecisionTreeRegressor())\n",
    "    models['extra'] = MultiOutputRegressor(ExtraTreeRegressor())\n",
    "    models['svml'] = MultiOutputRegressor(SVR(kernel='linear'))\n",
    "    models['svmp'] = MultiOutputRegressor(SVR(kernel='poly'))\n",
    "    c_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for c in c_values:\n",
    "        models['svmr'+str(c)] = SVR(C=c)\n",
    "    # ensemble models\n",
    "    n_trees = 100\n",
    "    models['ada'] = MultiOutputRegressor(AdaBoostRegressor(n_estimators=n_trees))\n",
    "    models['bag'] = MultiOutputRegressor(BaggingRegressor(n_estimators=n_trees))\n",
    "    models['rf'] = MultiOutputRegressor(RandomForestRegressor(n_estimators=n_trees))\n",
    "    models['et'] = MultiOutputRegressor(ExtraTreesRegressor(n_estimators=n_trees))\n",
    "    models['gbm'] = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=n_trees))\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models\n",
    "\n",
    "# create a feature preparation pipeline for a model\n",
    "def make_pipeline(model):\n",
    "    steps = list()\n",
    "    # standardization\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    # normalization\n",
    "    steps.append(('normalize', MinMaxScaler()))\n",
    "    # the model\n",
    "    steps.append(('model', model))\n",
    "    # create pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric):\n",
    "    # create the pipeline\n",
    "    pipeline = make_pipeline(model)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# evaluate a model and try to trap errors and and hide warnings\n",
    "def robust_evaluate_model(X, y, model, folds, metric):\n",
    "    scores = None\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            scores = evaluate_model(X, y, model, folds, metric)\n",
    "    except:\n",
    "        scores = None\n",
    "    return scores\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, folds=10, metric='accuracy'):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        # evaluate the model\n",
    "        scores = robust_evaluate_model(X, y, model, folds, metric)\n",
    "        # show process\n",
    "        if scores is not None:\n",
    "            # store a result\n",
    "            results[name] = scores\n",
    "            mean_score, std_score = np.mean(scores), np.std(scores)\n",
    "            print('>%s: %.3f (+/-%.3f)' % (name, mean_score, std_score))\n",
    "        else:\n",
    "            print('>%s: error' % name)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 190 models\n",
      ">lr: -1013531858180976017408.000 (+/-2387938681014755786752.000)\n",
      ">lasso-0.0: -0.063 (+/-0.003)\n",
      ">lasso-0.1: -0.107 (+/-0.003)\n",
      ">lasso-0.2: -0.107 (+/-0.003)\n",
      ">lasso-0.3: -0.107 (+/-0.003)\n",
      ">lasso-0.4: -0.107 (+/-0.003)\n",
      ">lasso-0.5: -0.107 (+/-0.003)\n",
      ">lasso-0.6: -0.107 (+/-0.003)\n",
      ">lasso-0.7: -0.107 (+/-0.003)\n",
      ">lasso-0.8: -0.107 (+/-0.003)\n",
      ">lasso-0.9: -0.107 (+/-0.003)\n",
      ">lasso-1.0: -0.107 (+/-0.003)\n",
      ">ridge-0.0: -111737172849561398411264.000 (+/-314809984480779272454144.000)\n",
      ">ridge-0.1: -0.063 (+/-0.003)\n",
      ">ridge-0.2: -0.063 (+/-0.003)\n",
      ">ridge-0.3: -0.063 (+/-0.003)\n",
      ">ridge-0.4: -0.063 (+/-0.003)\n",
      ">ridge-0.5: -0.063 (+/-0.003)\n",
      ">ridge-0.6: -0.063 (+/-0.003)\n",
      ">ridge-0.7: -0.063 (+/-0.003)\n",
      ">ridge-0.8: -0.063 (+/-0.003)\n",
      ">ridge-0.9: -0.063 (+/-0.003)\n",
      ">ridge-1.0: -0.063 (+/-0.003)\n",
      ">en-0.0-0.0: -0.063 (+/-0.003)\n",
      ">en-0.0-0.1: -0.063 (+/-0.003)\n",
      ">en-0.0-0.2: -0.063 (+/-0.003)\n",
      ">en-0.0-0.3: -0.063 (+/-0.003)\n",
      ">en-0.0-0.4: -0.063 (+/-0.003)\n",
      ">en-0.0-0.5: -0.063 (+/-0.003)\n",
      ">en-0.0-0.6: -0.063 (+/-0.003)\n",
      ">en-0.0-0.7: -0.063 (+/-0.003)\n",
      ">en-0.0-0.8: -0.063 (+/-0.003)\n",
      ">en-0.0-0.9: -0.063 (+/-0.003)\n",
      ">en-0.0-1.0: -0.063 (+/-0.003)\n",
      ">en-0.1-0.0: -0.073 (+/-0.003)\n",
      ">en-0.1-0.1: -0.082 (+/-0.003)\n",
      ">en-0.1-0.2: -0.090 (+/-0.003)\n",
      ">en-0.1-0.3: -0.099 (+/-0.003)\n",
      ">en-0.1-0.4: -0.105 (+/-0.003)\n",
      ">en-0.1-0.5: -0.107 (+/-0.003)\n",
      ">en-0.1-0.6: -0.107 (+/-0.003)\n",
      ">en-0.1-0.7: -0.107 (+/-0.003)\n",
      ">en-0.1-0.8: -0.107 (+/-0.003)\n",
      ">en-0.1-0.9: -0.107 (+/-0.003)\n",
      ">en-0.1-1.0: -0.107 (+/-0.003)\n",
      ">en-0.2-0.0: -0.079 (+/-0.003)\n",
      ">en-0.2-0.1: -0.094 (+/-0.003)\n",
      ">en-0.2-0.2: -0.106 (+/-0.003)\n",
      ">en-0.2-0.3: -0.107 (+/-0.003)\n",
      ">en-0.2-0.4: -0.107 (+/-0.003)\n",
      ">en-0.2-0.5: -0.107 (+/-0.003)\n",
      ">en-0.2-0.6: -0.107 (+/-0.003)\n",
      ">en-0.2-0.7: -0.107 (+/-0.003)\n",
      ">en-0.2-0.8: -0.107 (+/-0.003)\n",
      ">en-0.2-0.9: -0.107 (+/-0.003)\n",
      ">en-0.2-1.0: -0.107 (+/-0.003)\n",
      ">en-0.3-0.0: -0.083 (+/-0.003)\n",
      ">en-0.3-0.1: -0.103 (+/-0.003)\n",
      ">en-0.3-0.2: -0.107 (+/-0.003)\n",
      ">en-0.3-0.3: -0.107 (+/-0.003)\n",
      ">en-0.3-0.4: -0.107 (+/-0.003)\n",
      ">en-0.3-0.5: -0.107 (+/-0.003)\n",
      ">en-0.3-0.6: -0.107 (+/-0.003)\n",
      ">en-0.3-0.7: -0.107 (+/-0.003)\n",
      ">en-0.3-0.8: -0.107 (+/-0.003)\n",
      ">en-0.3-0.9: -0.107 (+/-0.003)\n",
      ">en-0.3-1.0: -0.107 (+/-0.003)\n",
      ">en-0.4-0.0: -0.086 (+/-0.003)\n",
      ">en-0.4-0.1: -0.106 (+/-0.003)\n",
      ">en-0.4-0.2: -0.107 (+/-0.003)\n",
      ">en-0.4-0.3: -0.107 (+/-0.003)\n",
      ">en-0.4-0.4: -0.107 (+/-0.003)\n",
      ">en-0.4-0.5: -0.107 (+/-0.003)\n",
      ">en-0.4-0.6: -0.107 (+/-0.003)\n",
      ">en-0.4-0.7: -0.107 (+/-0.003)\n",
      ">en-0.4-0.8: -0.107 (+/-0.003)\n",
      ">en-0.4-0.9: -0.107 (+/-0.003)\n",
      ">en-0.4-1.0: -0.107 (+/-0.003)\n",
      ">en-0.5-0.0: -0.088 (+/-0.003)\n",
      ">en-0.5-0.1: -0.107 (+/-0.003)\n",
      ">en-0.5-0.2: -0.107 (+/-0.003)\n",
      ">en-0.5-0.3: -0.107 (+/-0.003)\n",
      ">en-0.5-0.4: -0.107 (+/-0.003)\n",
      ">en-0.5-0.5: -0.107 (+/-0.003)\n",
      ">en-0.5-0.6: -0.107 (+/-0.003)\n",
      ">en-0.5-0.7: -0.107 (+/-0.003)\n",
      ">en-0.5-0.8: -0.107 (+/-0.003)\n",
      ">en-0.5-0.9: -0.107 (+/-0.003)\n",
      ">en-0.5-1.0: -0.107 (+/-0.003)\n",
      ">en-0.6-0.0: -0.090 (+/-0.003)\n",
      ">en-0.6-0.1: -0.107 (+/-0.003)\n",
      ">en-0.6-0.2: -0.107 (+/-0.003)\n",
      ">en-0.6-0.3: -0.107 (+/-0.003)\n",
      ">en-0.6-0.4: -0.107 (+/-0.003)\n",
      ">en-0.6-0.5: -0.107 (+/-0.003)\n",
      ">en-0.6-0.6: -0.107 (+/-0.003)\n",
      ">en-0.6-0.7: -0.107 (+/-0.003)\n",
      ">en-0.6-0.8: -0.107 (+/-0.003)\n",
      ">en-0.6-0.9: -0.107 (+/-0.003)\n",
      ">en-0.6-1.0: -0.107 (+/-0.003)\n",
      ">en-0.7-0.0: -0.092 (+/-0.003)\n",
      ">en-0.7-0.1: -0.107 (+/-0.003)\n",
      ">en-0.7-0.2: -0.107 (+/-0.003)\n",
      ">en-0.7-0.3: -0.107 (+/-0.003)\n",
      ">en-0.7-0.4: -0.107 (+/-0.003)\n",
      ">en-0.7-0.5: -0.107 (+/-0.003)\n",
      ">en-0.7-0.6: -0.107 (+/-0.003)\n",
      ">en-0.7-0.7: -0.107 (+/-0.003)\n",
      ">en-0.7-0.8: -0.107 (+/-0.003)\n",
      ">en-0.7-0.9: -0.107 (+/-0.003)\n",
      ">en-0.7-1.0: -0.107 (+/-0.003)\n",
      ">en-0.8-0.0: -0.093 (+/-0.003)\n",
      ">en-0.8-0.1: -0.107 (+/-0.003)\n",
      ">en-0.8-0.2: -0.107 (+/-0.003)\n",
      ">en-0.8-0.3: -0.107 (+/-0.003)\n",
      ">en-0.8-0.4: -0.107 (+/-0.003)\n",
      ">en-0.8-0.5: -0.107 (+/-0.003)\n",
      ">en-0.8-0.6: -0.107 (+/-0.003)\n",
      ">en-0.8-0.7: -0.107 (+/-0.003)\n",
      ">en-0.8-0.8: -0.107 (+/-0.003)\n",
      ">en-0.8-0.9: -0.107 (+/-0.003)\n",
      ">en-0.8-1.0: -0.107 (+/-0.003)\n",
      ">en-0.9-0.0: -0.094 (+/-0.003)\n",
      ">en-0.9-0.1: -0.107 (+/-0.003)\n",
      ">en-0.9-0.2: -0.107 (+/-0.003)\n",
      ">en-0.9-0.3: -0.107 (+/-0.003)\n",
      ">en-0.9-0.4: -0.107 (+/-0.003)\n",
      ">en-0.9-0.5: -0.107 (+/-0.003)\n",
      ">en-0.9-0.6: -0.107 (+/-0.003)\n",
      ">en-0.9-0.7: -0.107 (+/-0.003)\n",
      ">en-0.9-0.8: -0.107 (+/-0.003)\n",
      ">en-0.9-0.9: -0.107 (+/-0.003)\n",
      ">en-0.9-1.0: -0.107 (+/-0.003)\n",
      ">en-1.0-0.0: -0.095 (+/-0.003)\n",
      ">en-1.0-0.1: -0.107 (+/-0.003)\n",
      ">en-1.0-0.2: -0.107 (+/-0.003)\n",
      ">en-1.0-0.3: -0.107 (+/-0.003)\n",
      ">en-1.0-0.4: -0.107 (+/-0.003)\n",
      ">en-1.0-0.5: -0.107 (+/-0.003)\n",
      ">en-1.0-0.6: -0.107 (+/-0.003)\n",
      ">en-1.0-0.7: -0.107 (+/-0.003)\n",
      ">en-1.0-0.8: -0.107 (+/-0.003)\n",
      ">en-1.0-0.9: -0.107 (+/-0.003)\n",
      ">en-1.0-1.0: -0.107 (+/-0.003)\n",
      ">huber: -0.064 (+/-0.004)\n",
      ">lars: -125284.674 (+/-305118.983)\n",
      ">llars: -0.107 (+/-0.003)\n",
      ">pa: -0.142 (+/-0.032)\n",
      ">ranscac: -15239082331421136896.000 (+/-45706068432667295744.000)\n",
      ">sgd: -0.066 (+/-0.003)\n",
      ">theil: -0.073 (+/-0.006)\n",
      ">knn-1: -0.115 (+/-0.004)\n",
      ">knn-2: -0.085 (+/-0.004)\n",
      ">knn-3: -0.076 (+/-0.003)\n",
      ">knn-4: -0.071 (+/-0.004)\n",
      ">knn-5: -0.068 (+/-0.003)\n",
      ">knn-6: -0.066 (+/-0.003)\n",
      ">knn-7: -0.065 (+/-0.003)\n",
      ">knn-8: -0.064 (+/-0.003)\n",
      ">knn-9: -0.064 (+/-0.003)\n",
      ">knn-10: -0.064 (+/-0.003)\n",
      ">knn-11: -0.063 (+/-0.003)\n",
      ">knn-12: -0.063 (+/-0.003)\n",
      ">knn-13: -0.063 (+/-0.003)\n",
      ">knn-14: -0.063 (+/-0.003)\n",
      ">knn-15: -0.063 (+/-0.003)\n",
      ">knn-16: -0.063 (+/-0.003)\n",
      ">knn-17: -0.062 (+/-0.003)\n",
      ">knn-18: -0.062 (+/-0.003)\n",
      ">knn-19: -0.062 (+/-0.003)\n",
      ">knn-20: -0.062 (+/-0.003)\n",
      ">cart: -0.112 (+/-0.005)\n",
      ">extra: -0.113 (+/-0.005)\n",
      ">svml: -0.064 (+/-0.004)\n",
      ">svmp: -0.059 (+/-0.003)\n",
      ">svmr0.1: nan (+/-nan)\n",
      ">svmr0.2: nan (+/-nan)\n",
      ">svmr0.3: nan (+/-nan)\n",
      ">svmr0.4: nan (+/-nan)\n",
      ">svmr0.5: nan (+/-nan)\n",
      ">svmr0.6: nan (+/-nan)\n",
      ">svmr0.7: nan (+/-nan)\n",
      ">svmr0.8: nan (+/-nan)\n",
      ">svmr0.9: nan (+/-nan)\n",
      ">svmr1.0: nan (+/-nan)\n",
      ">ada: -0.070 (+/-0.005)\n",
      ">bag: -0.059 (+/-0.004)\n",
      ">rf: -0.059 (+/-0.004)\n",
      ">et: -0.062 (+/-0.003)\n",
      ">gbm: -0.055 (+/-0.003)\n"
     ]
    }
   ],
   "source": [
    "# get model list\n",
    "models = get_models_multioutput()   \n",
    "# evaluate models\n",
    "results = evaluate_models(X_train, y_train, models, metric='neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(results, maximize=True, top_n=10):\n",
    "    # check for no results\n",
    "    if len(results) == 0:\n",
    "        print('no results')\n",
    "        return\n",
    "    # determine how many results to summarize\n",
    "    n = min(top_n, len(results))\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k,np.mean(v)) for k,v in results.items()]\n",
    "    \n",
    "    mean_scores_nonan = []\n",
    "    for k in range(len(mean_scores)) :\n",
    "        if  math.isnan( mean_scores[k][1] )!= True :\n",
    "            mean_scores_nonan.append(mean_scores[k])      \n",
    "    \n",
    "    # sort tuples by mean score\n",
    "    mean_scores_nonan = sorted(mean_scores_nonan, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores_nonan = list(reversed(mean_scores_nonan))\n",
    "    # retrieve the top n for summarization\n",
    "    names = [x[0] for x in mean_scores_nonan[:n]]\n",
    "    scores = [results[x[0]] for x in mean_scores_nonan[:n]]\n",
    "    # print the top n\n",
    "    print()\n",
    "    for i in range(n):\n",
    "        name = names[i]\n",
    "        mean_score, std_score = np.mean(results[name]), np.std(results[name])\n",
    "        print('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' % (i+1, name, mean_score, std_score))\n",
    "    # boxplot for the top n\n",
    "    pyplot.boxplot(scores, labels=names)\n",
    "    _, labels = pyplot.xticks()\n",
    "    pyplot.setp(labels, rotation=90)\n",
    "    #pyplot.savefig('spotcheck.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank=1, Name=gbm, Score=-0.055 (+/- 0.003)\n",
      "Rank=2, Name=bag, Score=-0.059 (+/- 0.004)\n",
      "Rank=3, Name=rf, Score=-0.059 (+/- 0.004)\n",
      "Rank=4, Name=svmp, Score=-0.059 (+/- 0.003)\n",
      "Rank=5, Name=et, Score=-0.062 (+/- 0.003)\n",
      "Rank=6, Name=knn-20, Score=-0.062 (+/- 0.003)\n",
      "Rank=7, Name=knn-19, Score=-0.062 (+/- 0.003)\n",
      "Rank=8, Name=knn-18, Score=-0.062 (+/- 0.003)\n",
      "Rank=9, Name=knn-17, Score=-0.062 (+/- 0.003)\n",
      "Rank=10, Name=knn-16, Score=-0.063 (+/- 0.003)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_results(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Selected Model - Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.4925 with stdev 0.0221\n",
      "MSE: 0.0546 with stdev 0.0029\n"
     ]
    }
   ],
   "source": [
    "# The Selected Model - Gradient boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "estimators = [('standardize', StandardScaler()),\n",
    "             ('reg', MultiOutputRegressor(GradientBoostingRegressor(random_state=seed)))]\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_validate(pipeline, X_train, y_train, cv=kfold, scoring=['r2','neg_mean_squared_error'])\n",
    "\n",
    "r2_arr = results['test_r2']\n",
    "mse_arr = results['test_neg_mean_squared_error']*-1\n",
    "\n",
    "print(f\"R^2: {r2_arr.mean():.4f} with stdev {r2_arr.std():.4f}\")\n",
    "print(f\"MSE: {mse_arr.mean():.4f} with stdev {mse_arr.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputRegressor(estimator=GradientBoostingRegressor(alpha=0.9,\n",
      "                                                         ccp_alpha=0.0,\n",
      "                                                         criterion='friedman_mse',\n",
      "                                                         init=None,\n",
      "                                                         learning_rate=0.1,\n",
      "                                                         loss='ls', max_depth=3,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=100,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='deprecated',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=1.0,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False),\n",
      "                     n_jobs=None)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Model Tuning \"\"\"\n",
    "# Import \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# Initialize the classifier\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "reg = MultiOutputRegressor(GradientBoostingRegressor(random_state=seed))\n",
    "print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 15.9min finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {'estimator__n_estimators':[50, 75,100,200,300, 500], \n",
    "              'estimator__max_depth' : [2,3,5,8,10, None],\n",
    "              'estimator__min_samples_split' : [2,5,7,9,12],\n",
    "              'estimator__min_samples_leaf' : [1,3,5,7,9]\n",
    "             }\n",
    "\n",
    "# Perform grid search \n",
    "grid_obj = RandomizedSearchCV(reg, param_distributions=parameters,n_iter = 50,scoring='neg_mean_squared_error', verbose=10, n_jobs=-1)\n",
    "# Fit the grid search object to the training data \n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "# Get the estimator\n",
    "best_reg = grid_fit.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model\n",
      "R^2 score :  0.4899010925056648\n",
      "MSE :  0.05459027872088544\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Tuned Model')\n",
    "print('R^2 score : ', best_reg.score(X_test, y_test))\n",
    "print('MSE : ', mean_squared_error(y_test, best_reg.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputRegressor(estimator=GradientBoostingRegressor(alpha=0.9,\n",
      "                                                         ccp_alpha=0.0,\n",
      "                                                         criterion='friedman_mse',\n",
      "                                                         init=None,\n",
      "                                                         learning_rate=0.1,\n",
      "                                                         loss='ls', max_depth=3,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=5,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=75,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='deprecated',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=1.0,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False),\n",
      "                     n_jobs=None)\n"
     ]
    }
   ],
   "source": [
    "print( best_reg ) \n",
    "\n",
    "#  保存最佳网格参数\n",
    "pklsave(best_reg, 'sav/best_reg.sav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 采用线性回归方法 得分 R^2:0.4084 MSE:0.0633\n",
    "- 采用Gradient boosting方法 得分 R^2: 0.4925 MSE: 0.0546 \n",
    "- 采用调参后的Gradient boosting方法 得分 R^2 score:0.4899  MSE:0.0546\n",
    "- 最终模型准确率并不高，可能是因为特征提取的还不够 需要更多特征 比如提取用户 对每一种推送offer接收数量、完成数量和完成/接收率，以及提取用户的年龄分组\n",
    "    \n",
    "    \n",
    "- Using linear regression method， Score R^2: 0.4084  MSE: 0.0633\n",
    "- Using Gradient boosting method， Score R^2: 0.4925  MSE: 0.0546\n",
    "- Tuning the Gradient boosting method, Score R^2: 0.4899  MSE: 0.0546\n",
    "- The accuracy of the final model is not high. It may be that the feature extraction is not enough. More features are needed, such as extracting users' received count, completed count, and completed/received rates for each type of pushed offer , as well as users' age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "机器学习，预测用户完成率",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221.176px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
